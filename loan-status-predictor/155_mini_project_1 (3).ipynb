{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UjGW-r2oCKXP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from pandas import DataFrame as df\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler,LabelEncoder, OneHotEncoder,QuantileTransformer, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "grade_mapping = {'A': 7, 'B': 6, 'C': 5, 'D': 4, 'E': 3, 'F': 2, 'G': 1}\n",
    "\n",
    "emp_mapping = {'1 year': 1,\n",
    " '10+ years': 10,\n",
    " '2 years': 2,\n",
    " '3 years': 3,\n",
    " '4 years': 4,\n",
    " '5 years': 5,\n",
    " '6 years': 6,\n",
    " '7 years': 7,\n",
    " '8 years': 8,\n",
    " '9 years': 9,\n",
    " '< 1 year': 0.5}\n",
    "\n",
    "\n",
    "def prepare_data(filename, drop_cols, percent_cols, date_cols, test=False):\n",
    "    data = pd.read_csv(filename, index_col='id')\n",
    "\n",
    "    for col in drop_cols:\n",
    "        data.drop(col, axis=1, inplace=True) \n",
    "\n",
    "    for col in percent_cols:\n",
    "        data[col] = pd.to_numeric(data[col].str.strip('%')).div(100)\n",
    "\n",
    "    data = data.replace({\"grade\": grade_mapping})\n",
    "    data = data.replace({\"emp_length\": emp_mapping})\n",
    "\n",
    "\n",
    "    for col in date_cols:\n",
    "        data[col] = pd.to_numeric(data[col].str[4:])\n",
    "\n",
    "    if not test: \n",
    "        X = data.iloc[:,:-1]\n",
    "\n",
    "        y = data.iloc[:, -1]\n",
    "        return X,y\n",
    "\n",
    "    else:\n",
    "        X = data\n",
    "\n",
    "        return X, _\n",
    "\n",
    "def make_balanced_test_set(filename, drop_cols, percent_cols, date_cols, test=False):\n",
    "    data = pd.read_csv(filename, index_col='id')\n",
    "\n",
    "    for col in drop_cols:\n",
    "        data.drop(col, axis=1, inplace=True) \n",
    "\n",
    "    for col in percent_cols:\n",
    "        data[col] = pd.to_numeric(data[col].str.strip('%')).div(100)\n",
    "\n",
    "    data = data.replace({\"grade\": grade_mapping})\n",
    "    data = data.replace({\"emp_length\": emp_mapping})\n",
    "\n",
    "\n",
    "    for col in date_cols:\n",
    "        data[col] = pd.to_numeric(data[col].str[4:])\n",
    "\n",
    "    X_zeros = data[data['loan_status'] == 'Fully Paid']\n",
    "    X_ones = data[data['loan_status'] == 'Charged Off']\n",
    "    balanced = (X_ones.iloc[:30000].append(X_ones.iloc[:30000]))\n",
    "\n",
    "    X = balanced.iloc[:,:-1]\n",
    "    y = balanced.iloc[:, -1]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lVKIz8t-oAmd"
   },
   "outputs": [],
   "source": [
    "\n",
    "# names of columns to drop \n",
    "drop = ['sub_grade',\n",
    "        'emp_title',\n",
    "        'title',\n",
    "        'zip_code',\n",
    "        'mort_acc',\n",
    "        'application_type', \n",
    "       'verification_status']\n",
    "\n",
    "# names of percent columns lol\n",
    "percent = ['int_rate', 'revol_util']\n",
    "\n",
    "# cols with dates to converts to ints\n",
    "date = ['earliest_cr_line', 'issue_d']\n",
    "\n",
    "X_train, y_train = prepare_data('LOANS_TRAIN.csv', drop, percent, date, test=False)\n",
    "\n",
    "# optional code to split training set into a dummy test set \n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=34534)\n",
    "\n",
    "X_test_real, _ = prepare_data('LOANS_TEST.csv', drop, percent, date, test=True)\n",
    "\n",
    "# balanced validation set to help test models\n",
    "balanced_X, balanced_y = make_balanced_test_set('LOANS_TRAIN.csv', drop, percent, date, test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ISy3k3OXmREi"
   },
   "outputs": [],
   "source": [
    "# models we have tried in pipe\n",
    "\n",
    "lgr = LogisticRegression(C= 1e-3, solver='saga', max_iter= 1000, random_state = 2222, \n",
    "                         class_weight = {'Fully Paid': 1, 'Charged Off': 6})\n",
    "sgd = SGDClassifier(loss = 'log',max_iter=1000, tol=1e-3, early_stopping = True)\n",
    "lgrcv = LogisticRegressionCV(max_iter= 9)\n",
    "rf = RandomForestClassifier(n_estimators=5, random_state=422, max_depth = 12)\n",
    "clf = MLPClassifier(\n",
    "                    alpha=1e-5,\n",
    "                    solver = 'sgd',\n",
    "                    hidden_layer_sizes=(50, 30, 25, 10,),\n",
    "                    activation = 'logistic', \n",
    "                    batch_size = 50,\n",
    "                    early_stopping = True, \n",
    "                    random_state=123, \n",
    "                    max_iter=1000)\n",
    "\n",
    "\n",
    "# can stack models in ensemble\n",
    "models = [('rf',rf),('lgr', lgr)]\n",
    "stacking = StackingClassifier(estimators=models)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ZuRPyC0oWzx"
   },
   "outputs": [],
   "source": [
    "num_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat_features = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer()), ('poly',PolynomialFeatures(degree = 4))\n",
    "    , ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers = [('num', num_transformer, num_features), \n",
    "                                                 ('cat', cat_transformer, cat_features)])\n",
    "\n",
    "\n",
    "steps=[('preprocessor', preprocessor),('classifier', lgr)]\n",
    "pipe = Pipeline(steps)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "print(pipe.score(X_train, y_train))\n",
    "print(pipe.score(balanced_X, balanced_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IxQ_SKPzmWmO"
   },
   "outputs": [],
   "source": [
    "# code to output submisson\n",
    "predictions = pipe.predict_proba(X_test_real)[:,0]\n",
    "ids = X_test_real.index\n",
    "df = pd.DataFrame({'id': ids, 'loan_status': predictions})\n",
    "out = df.to_csv('newsubmission10.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xh_K2ypOA_HB"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "155 mini project 1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
